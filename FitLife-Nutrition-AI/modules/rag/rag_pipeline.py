
import os
import sys
from pathlib import Path
import yaml
from typing import Dict, List, Optional
import numpy as np
import pandas as pd

class NutritionRAGPipeline:
    """Pipeline RAG complet pour la nutrition - Version Windows"""
    
    def __init__(self, config_path: Optional[str] = None):
        # Configuration pour √©viter les erreurs de biblioth√®que sur Windows
        os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'
        
        # D√©finir le chemin racine du projet (FitLife-Nutrition-AI)
        self.root_dir = Path(__file__).resolve().parent.parent.parent
        print(f"DEBUG: Root dir resolved to: {self.root_dir}")
        
        self.config = self._load_config(config_path)
        self._init_components()
    
    def _load_config(self, config_path: Optional[str] = None):
        """Charge la configuration depuis YAML"""
        default_config = {
            "data": {
                "csv_path": str(self.root_dir / "data" / "cleaned_nutrition_data.csv"),
                "sample_size": None
            },
            "embedding": {
                "model_name": "all-MiniLM-L6-v2",
                "batch_size": 32,
                "save_embeddings": True
            },
            "indexing": {
                "index_type": "IndexFlatL2",
                "save_index": True
            },
            "llm": {
                "enabled": True,
                "backend": "ollama",
                "model_name": "llama3.2:1b",
                "ollama_base_url": "http://localhost:11434",
                "temperature": 0.7,
                "max_tokens": 300
            },
            "retrieval": {
                "default_k": 10,
                "use_cache": True
            },
            "paths": {
                "embeddings": str(self.root_dir / "models" / "embeddings.npy"),
                "index": str(self.root_dir / "models" / "faiss_index.index")
            }
        }
        
        if config_path and os.path.exists(config_path):
            with open(config_path, 'r') as f:
                user_config = yaml.safe_load(f)
                # Fusionner r√©cursivement
                for key in default_config:
                    if key in user_config:
                        if isinstance(default_config[key], dict) and isinstance(user_config[key], dict):
                            default_config[key].update(user_config[key])
                        else:
                            default_config[key] = user_config[key]
        
        return default_config
    
    def _init_components(self):
        """Initialise tous les composants du pipeline"""
        print("=" * 60)
        print("üß† INITIALISATION DU PIPELINE NUTRITION RAG - Windows")
        print("=" * 60)
        
        # Cr√©er les r√©pertoires n√©cessaires
        models_dir = self.root_dir / "models"
        os.makedirs(models_dir, exist_ok=True)
        
        # 1. Pr√©processing
        print("\nüì• √âTAPE 1: PR√âPROCESSING")
        from modules.rag.data_processor import NutritionDataProcessor
        
        csv_path = self.config["data"]["csv_path"]
        if not os.path.exists(csv_path):
            print(f"   ‚ö†Ô∏è Fichier de donn√©es non trouv√©: {csv_path}")
            print(f"   üìå Cr√©ation de donn√©es d'exemple...")
            self._create_sample_data()
        
        self.preprocessor = NutritionDataProcessor(csv_path)
        self.df = self.preprocessor.run_pipeline()
        
        # √âchantillonner si n√©cessaire
        sample_size = self.config["data"]["sample_size"]
        if sample_size and sample_size < len(self.df):
            print(f"   üìä √âchantillonnage: {sample_size} aliments")
            self.df = self.df.sample(sample_size, random_state=42).reset_index(drop=True)
        
        print(f"   ‚úì Donn√©es charg√©es: {len(self.df)} aliments")
        
        # 2. Embedding
        print("\nüî§ √âTAPE 2: EMBEDDING")
        from modules.rag.embeddings import NutritionEmbedder
        
        self.embedder = NutritionEmbedder(
            model_name=self.config["embedding"]["model_name"]
        )
        
        # Charger ou cr√©er les embeddings
        embeddings_path = self.config["paths"]["embeddings"]
        if os.path.exists(embeddings_path):
            print("   ‚úì Chargement des embeddings sauvegard√©s")
            self.embeddings = np.load(embeddings_path)
        else:
            print("   üìù Cr√©ation des embeddings...")
            texts = self.df['food_description'].tolist()
            self.embeddings = self.embedder.create_embeddings(
                texts, 
                batch_size=self.config["embedding"]["batch_size"]
            )
            if self.config["embedding"]["save_embeddings"]:
                np.save(embeddings_path, self.embeddings)
                print(f"   üíæ Embeddings sauvegard√©s: {embeddings_path}")
        
        # 3. Indexation
        print("\nüìä √âTAPE 3: INDEXATION")
        from modules.rag.indexer import FaissIndexer
        
        dimension = self.embeddings.shape[1]
        self.indexer = FaissIndexer(dimension)
        
        # Charger ou cr√©er l'index
        index_path = self.config["paths"]["index"]
        if os.path.exists(index_path):
            print("   ‚úì Chargement de l'index FAISS sauvegard√©")
            self.indexer.load_index(index_path)
        else:
            self.indexer.add_embeddings(self.embeddings)
            if self.config["indexing"]["save_index"]:
                self.indexer.save_index(index_path)
                print(f"   üíæ Index sauvegard√©: {index_path}")
        
        # 4. Retriever
        print("\nüîç √âTAPE 4: RETRIEVER")
        from modules.rag.retriever import NutritionRetriever
        
        self.retriever = NutritionRetriever(
            self.df, 
            self.embedder, 
            self.indexer
        )
        
        # 5. Augmenter de contexte
        print("\nüé≠ √âTAPE 5: AUGMENTATION DE CONTEXTE")
        from modules.rag.context_augmenter import ContextAugmenter
        self.augmenter = ContextAugmenter()
        
        # 6. LLM (optionnel)
        if self.config["llm"]["enabled"]:
            print("\nü§ñ √âTAPE 6: INITIALISATION LLM")
            from modules.rag.llm_generator import LocalLLMGenerator
            
            try:
                self.generator = LocalLLMGenerator(
                    model_name=self.config["llm"]["model_name"],
                    base_url=self.config["llm"]["ollama_base_url"],
                    backend=self.config["llm"]["backend"]
                )
                self.use_llm = True
                print(f"   ‚úì LLM pr√™t (backend: {self.generator.backend})")
            except Exception as e:
                print(f"   ‚ö†Ô∏è LLM non disponible: {e}")
                print("   ‚ö†Ô∏è Utilisation du mode simple")
                self.use_llm = False
        else:
            self.use_llm = False
        
        print("\n" + "=" * 60)
        print("‚úÖ PIPELINE PR√äT √Ä L'EMPLOI")
        print("=" * 60)
    
    def _create_sample_data(self):
        """Cr√©e des donn√©es d'exemple si le fichier CSV n'existe pas"""
        sample_data = {
            'food_name': [
                'Pomme', 'Banane', 'Poulet grill√©', 'Saumon', 'Brocoli',
                'Riz brun', '≈íuf', 'Yaourt grec', 'Amandes', 'Avocat'
            ],
            'calories_kcal': [52, 89, 165, 208, 34, 111, 155, 59, 579, 160],
            'protein_g': [0.3, 1.1, 31.0, 20.0, 2.8, 2.6, 13.0, 10.0, 21.2, 2.0],
            'carbs_g': [13.8, 22.8, 0.0, 0.0, 6.6, 23.0, 1.1, 3.6, 21.6, 8.5],
            'fat_g': [0.2, 0.3, 3.6, 13.0, 0.4, 0.9, 11.0, 0.4, 49.9, 14.7],
            'fiber_g': [2.4, 2.6, 0.0, 0.0, 2.6, 1.8, 0.0, 0.0, 12.5, 6.7],
            'sugars_g': [10.4, 12.2, 0.0, 0.0, 1.7, 0.4, 1.1, 3.6, 4.4, 0.7],
            'food_category': [
                'Fruit', 'Fruit', 'Viande', 'Poisson', 'L√©gume',
                'C√©r√©ale', 'Produit animal', 'Laitier', 'Noix', 'L√©gume'
            ],
            'health_score': [85.0, 82.0, 75.0, 88.0, 92.0, 72.0, 70.0, 68.0, 76.0, 80.0]
        }
        
        df = pd.DataFrame(sample_data)
        df.to_csv(self.config["data"]["csv_path"], index=False)
        print(f"   ‚úì Donn√©es d'exemple cr√©√©es: {self.config['data']['csv_path']}")
    
    def query(self, user_query: str, k: int = None, filters: Dict = None):
        """Ex√©cute une requ√™te compl√®te"""
        if k is None:
            k = self.config["retrieval"]["default_k"]
        
        print(f"\nüéØ REQU√äTE: '{user_query}'")
        
        # R√©cup√©ration
        retrieved_foods = self.retriever.retrieve(
            query=user_query,
            k=k,
            filters=filters,
            use_cache=self.config["retrieval"]["use_cache"]
        )
        
        if retrieved_foods.empty:
            return {
                "response": "‚ùå Aucun aliment correspondant trouv√©.",
                "foods": [],
                "used_llm": False,
                "query": user_query,
                "foods_count": 0,
                "top_categories": [],
                "similarity_scores": []
            }
        
        # Augmentation du contexte
        context = self.augmenter.augment_context(user_query, retrieved_foods)
        
        # G√©n√©ration de la r√©ponse
        if self.use_llm:
            query_type = self.augmenter.detect_query_type(user_query)
            style_map = {
                'comparison': 'comparison_specialist',
                'recommendation': 'nutrition_expert',
                'analysis': 'nutrition_expert',
                'simple': 'simple_assistant'
            }
            style = style_map.get(query_type, 'simple_assistant')
            
            try:
                response = self.generator.generate_response(
                    query=user_query,
                    context=context,
                    style=style,
                    temperature=self.config["llm"]["temperature"],
                    max_tokens=self.config["llm"]["max_tokens"]
                )
                used_llm = True
            except Exception as e:
                print(f"   ‚ö†Ô∏è Erreur g√©n√©ration LLM: {e}")
                response = self._generate_simple_response(user_query, retrieved_foods)
                used_llm = False
        else:
            response = self._generate_simple_response(user_query, retrieved_foods)
            used_llm = False
        
        # Pr√©paration des r√©sultats
        result = {
            "response": response,
            "foods": retrieved_foods.head(5).to_dict('records'),
            "used_llm": used_llm,
            "query": user_query,
            "foods_count": len(retrieved_foods),
            "top_categories": self.retriever.get_top_categories(retrieved_foods, 3),
            "similarity_scores": retrieved_foods['similarity_score'].head(5).tolist()
        }
        
        print(f"   ‚úì {result['foods_count']} aliments trouv√©s")
        if result['top_categories']:
            print(f"   üìÅ Cat√©gories: {', '.join(result['top_categories'])}")
        
        return result
    
    def _generate_simple_response(self, query, foods):
        """G√©n√®re une r√©ponse simple sans LLM"""
        if foods.empty:
            return f"‚ùå Aucun aliment trouv√© pour la requ√™te : '{query}'"
        
        top_foods = foods.head(3)
        response_lines = [f"‚úÖ **R√©sultats pour '{query}'**", ""]
        
        for i, (_, food) in enumerate(top_foods.iterrows(), 1):
            response_lines.append(f"**{i}. {food['food_name']}**")
            response_lines.append(f"   ‚Ä¢ Cat√©gorie: {food.get('food_category', 'N/A')}")
            response_lines.append(f"   ‚Ä¢ Calories: {food.get('calories_kcal', 0)} kcal")
            response_lines.append(f"   ‚Ä¢ Prot√©ines: {food.get('protein_g', 0)}g")
            response_lines.append(f"   ‚Ä¢ Score sant√©: {food.get('health_score', 'N/A')}")
            response_lines.append(f"   ‚Ä¢ Similarit√©: {food.get('similarity_score', 0)*100:.1f}%")
            response_lines.append("")
        
        response_lines.append("üí° *Pour une analyse plus d√©taill√©e, activez le mode IA dans les param√®tres.*")
        
        return "\\n".join(response_lines)
    
    def get_statistics(self):
        """Retourne des statistiques sur les donn√©es"""
        stats = {
            "total_foods": len(self.df),
            "categories": self.df['food_category'].nunique() if 'food_category' in self.df.columns else 0,
            "columns": list(self.df.columns),
            "memory_usage": round(self.df.memory_usage(deep=True).sum() / 1024**2, 2)  # MB
        }
        
        if 'health_score' in self.df.columns:
            stats.update({
                "avg_health_score": round(self.df['health_score'].mean(), 1),
                "min_health_score": round(self.df['health_score'].min(), 1),
                "max_health_score": round(self.df['health_score'].max(), 1)
            })
        
        # Statistiques nutritionnelles
        if 'calories_kcal' in self.df.columns:
            stats['avg_calories'] = round(self.df['calories_kcal'].mean(), 1)
        
        if 'protein_g' in self.df.columns:
            stats['avg_protein'] = round(self.df['protein_g'].mean(), 1)
        
        return stats
    
    def save_pipeline(self):
        """Sauvegarde l'√©tat du pipeline"""
        state = {
            'config': self.config,
            'df_shape': self.df.shape,
            'embeddings_shape': self.embeddings.shape,
            'index_size': self.indexer.index.ntotal
        }
        
        with open('models/pipeline_state.json', 'w') as f:
            import json
            json.dump(state, f, indent=2)
        
        print("üíæ √âtat du pipeline sauvegard√©")
    
    def test_query(self, test_query="Quels aliments sont riches en prot√©ines ?"):
        """Test rapide du pipeline"""
        print("\nüß™ Test du pipeline...")
        results = self.query(test_query, k=3)
        print("\nüìù R√©sultats du test:")
        print(f"‚Ä¢ Requ√™te: {results['query']}")
        print(f"‚Ä¢ Aliments trouv√©s: {results['foods_count']}")
        print(f"‚Ä¢ LLM utilis√©: {results['used_llm']}")
        print(f"\nüìÑ R√©ponse (extrait):")
        print(results['response'][:200] + "...")
        return results

if __name__ == "__main__":
    # Test rapide si ex√©cut√© directement
    pipeline = NutritionRAGPipeline()
    stats = pipeline.get_statistics()
    print(f"\nüìä Statistiques des donn√©es:")
    print(f"‚Ä¢ Total aliments: {stats['total_foods']}")
    print(f"‚Ä¢ Cat√©gories: {stats['categories']}")
    if 'avg_health_score' in stats:
        print(f"‚Ä¢ Score sant√© moyen: {stats['avg_health_score']}")
    
    # Ex√©cuter un test
    test_results = pipeline.test_query()
